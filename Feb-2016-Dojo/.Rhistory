text <- gsub(email_address, " ", text)
text <- gsub("(.*)\\.com", " ", text)
text <- gsub("^[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}$", "", text)
text <- gsub("(.*)@state\\.gov", "", text)
# Remove line break
text <- gsub("\\n", " ", text)
# Remove H
text <- gsub(" H ", " ", text)
# Remove dates
week_days <- "(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)"
months <- "(January|February|March|April|May|June|July|August|September|October|November|December)"
# Remove dates
text <- gsub(week_days, " ", text)
text <- gsub(months, " ", text)
# More tidy up
text <- gsub("[A-P]M", " ", text)
text <- gsub("B\\d", " ", text)
text <- gsub("\"", " ", text)
text <- gsub("[T-t]o\\:|[F-f]rom\\:|H\\:|[F-f]or\\:|[S-s]ent\\:|[R-r][E-e]\\:|FW\\:|Fw\\:|Fwd\\:|mailto\\:|Tel\\:", " ", text)
text <- gsub("Subject\\:", "", text)
text <- gsub("\\/(.*)\\/", "", text)
text <- gsub("^http\\:(.*)", "", text)
head(text, 50)
tail(text, 50)
text[1000:1050]
# Correct some words
# Pis
text <- gsub("Pis", "Pls", text)
# More pre-processing:
text <- gsub("'", "", text)  # remove apostrophes
text <- gsub("•", "", text) # remove •
text <- gsub("[[:punct:]]", "", text)  # remove punctuation
text <- gsub("[[:cntrl:]]", " ", text)  # replace control characters with space
text <- gsub("^[[:space:]]+", "", text) # remove whitespace at beginning of documents
text <- gsub("[[:space:]]+$", "", text) # remove whitespace at end of documents
text <- gsub("[[:digit:]]", "", text) # remove numbers
text <- tolower(text)  # force to lowercase
text <- gsub("h ", "", text)
text <- gsub("w ", "", text)
text <- gsub("pm ", "", text)
text <- gsub("imagejpg", "", text)
emails$text <- text
empty <- emails$text == "" | emails$text == " "
emails <- emails[!empty, ]
dim(emails) # 7393    7
month_names <- as.character(unique(month))
month_names
length(week_days)
week_days
day_week
week_days_names <- as.character(unique(day_week))
week_days_names
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
month_names
month_names <- tolower(as.character(unique(month)))
week_days_names <- tolower(as.character(unique(day_week)))
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
plotRemoved(processed$documents, lower.thresh=seq(from = 1, to = 50, by = 1))
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 15)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
?prepDocuments
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 1)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 15)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 5)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
names(emails)
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence =~ released + to + from + from_to + date + day_month + day_week + month + year,
max.em.its=1,
data=out$meta,
seed=5926696,
init.type="Spectral")
t2 <- Sys.time()
t2-t1
beepr::beep(0)
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence =~ released + from_to + date,
max.em.its=1,
data=out$meta,
seed=5926696,
init.type="Spectral")
t2 <- Sys.time()
t2-t1
beepr::beep(0)
vocab[1:3]
vocab[1:30]
vocab[1:300]
documents[1:3]
out$meta$released[1:5]
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ released + from_to + s(date),
max.em.its=75,
data=out$meta,
seed=5926696,
init.type="Spectral")
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ from_to,
max.em.its=2,
data=out$meta,
seed=5926696,
init.type="Spectral")
names(stm_data)
names(emails)
stm_data <- emails[,c("released", "senderId", "to", "from",
"from_to", "text", "rawtext", "date",
"day_month", "day_week", "month", "year")]
month_names <- tolower(as.character(unique(month)))
week_days_names <- tolower(as.character(unique(day_week)))
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
plotRemoved(processed$documents, lower.thresh=seq(from = 1, to = 50, by = 1))
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ to + from + from_to + senderId + released + date + day_month + day_week + month + year,
max.em.its=2,
data=out$meta,
seed=5926696,
init.type="Spectral")
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ from_to + released + month + year,
max.em.its=1,
data=out$meta,
seed=5926696,
init.type="Spectral")
t2 <- Sys.time()
t2-t1
beepr::beep(0)
table(stm_data$released)
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = txt,
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = stm_data$rawtext,
id = NULL,
n = 2000,
labeltype ="frex") #prob
?stmBrowser
# stmBrowser
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = text,
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = "text",
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = restaurantsReviewFit,
data = out$meta,
covariates = c("delta.star", "review.effect", "average.stars",
"review.stars", "sentiment"),
text = "rawtext",
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = "rawtext",
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("from_to", "released", "month", "year"),
text = "text",
id = NULL,
n = 2000,
labeltype ="frex") #prob
names(email)
names(emails)
emails$text[1:6]
emails <- data.frame(to = dat$ExtractedTo,
from = dat$ExtractedFrom,
senderId = dat$SenderPersonId,
released = dat$ExtractedReleaseInPartOrFull,
emails = dat$ExtractedBodyText,
text = dat$ExtractedBodyText,
rawtext = dat$RawText,
date = date,
day_month = day_month,
day_week = day_week,
month = month,
year = year)
dim(emails)
names(emails)
# Classify emails as to and from Hillary
head(emails[,c("from", "senderId")], 50)
emails$from_to <- as.factor(ifelse(emails$senderId == 80, "From Hillary", "To Hillary"))
table(emails$from_to)
# From Hillary   To Hillary
#        1993         5795
# Quick look at emails text
head(emails$text, 10)
text <- emails$text
# Clean up a bit more
US_dp_state <- "U\\.S\\. Department of State(.*)STATE\\-"
text <- gsub(US_dp_state, "", text)
# Remove email address
email_address <- "<(.*)>"
text <- gsub(email_address, " ", text)
text <- gsub("(.*)\\.com", " ", text)
text <- gsub("^[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}$", "", text)
text <- gsub("(.*)@state\\.gov", "", text)
# Remove line break
text <- gsub("\\n", " ", text)
# Remove H
text <- gsub(" H ", " ", text)
# Remove dates
week_days <- "(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)"
months <- "(January|February|March|April|May|June|July|August|September|October|November|December)"
# Remove dates
text <- gsub(week_days, " ", text)
text <- gsub(months, " ", text)
# More tidy up
text <- gsub("[A-P]M", " ", text)
text <- gsub("B\\d", " ", text)
text <- gsub("\"", " ", text)
text <- gsub("[T-t]o\\:|[F-f]rom\\:|H\\:|[F-f]or\\:|[S-s]ent\\:|[R-r][E-e]\\:|FW\\:|Fw\\:|Fwd\\:|mailto\\:|Tel\\:", " ", text)
text <- gsub("Subject\\:", "", text)
text <- gsub("\\/(.*)\\/", "", text)
text <- gsub("^http\\:(.*)", "", text)
head(text, 50)
tail(text, 50)
text[1000:1050]
# Correct some words
# Pis
text <- gsub("Pis", "Pls", text)
# More pre-processing:
text <- gsub("'", "", text)  # remove apostrophes
text <- gsub("•", "", text) # remove •
text <- gsub("[[:punct:]]", "", text)  # remove punctuation
text <- gsub("[[:cntrl:]]", " ", text)  # replace control characters with space
text <- gsub("^[[:space:]]+", "", text) # remove whitespace at beginning of documents
text <- gsub("[[:space:]]+$", "", text) # remove whitespace at end of documents
text <- gsub("[[:digit:]]", "", text) # remove numbers
text <- tolower(text)  # force to lowercase
text <- gsub("h ", "", text)
text <- gsub("w ", "", text)
text <- gsub("pm ", "", text)
text <- gsub("imagejpg", "", text)
emails$text <- text
# remove empty emails
empty <- emails$text == "" | emails$text == " "
emails <- emails[!empty, ]
dim(emails) # 7393    7
emails$from_to <- factor(emails$from_to)
emails$released <- factor(emails$released)
emails$day_month <- factor(emails$day_month)
emails$year <- factor(emails$year)
stm_data <- emails[,c("released", "senderId", "to", "from",
"from_to", "emails" ,"text", "rawtext", "date",
"day_month", "day_week", "month", "year")]
month_names <- tolower(as.character(unique(month)))
week_days_names <- tolower(as.character(unique(day_week)))
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
plotRemoved(processed$documents, lower.thresh=seq(from = 1, to = 50, by = 1))
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
names(stm_data)
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ to + from + senderId + from_to + released + date + day_month + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
class(stm_data$year)
emails$from_to <- factor(emails$from_to)
emails$released <- factor(emails$released)
emails$day_month <- factor(emails$day_month)
emails$year <- factor(emails$year)
stm_data <- emails[,c("released", "senderId", "to", "from",
"from_to", "emails","text", "rawtext", "date",
"day_month", "day_week", "month", "year")]
month_names <- tolower(as.character(unique(month)))
week_days_names <- tolower(as.character(unique(day_week)))
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
# Choose frequency threshold
plotRemoved(processed$documents, lower.thresh=seq(from = 1, to = 50, by = 1))
#structure and index for usage in the stm model. Verify no-missingness.
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
#output will have object meta, documents, and vocab
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
##############
# released and fromH as a covariate in the topic prevalence
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ to + from + senderId + from_to + released + date + day_month + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
txt <- tolower(stm_data$text)
library(qdap)
txt <- tolower(stm_data$text)
?polarity
txt <- tolower(stm_data$text)
t1 <- Sys.time()
sentiments <- polarity(txt,
polarity.frame = qdapDictionaries::key.pol,
negators = qdapDictionaries::negation.words, n.before = 4, n.after = 2,
amplifiers = qdapDictionaries::amplification.words,
deamplifiers = qdapDictionaries::deamplification.words,
amplifier.weight = 0.8,
n.before = 4,
n.after = 2,
constrain = TRUE)
t2 <- Sys.time()
t2-t1
beep(0)
beepr::beep(0)
txt <- tolower(stm_data$text)
t1 <- Sys.time()
sentiments <- polarity(txt,
polarity.frame = qdapDictionaries::key.pol,
negators = qdapDictionaries::negation.words,
amplifiers = qdapDictionaries::amplification.words,
deamplifiers = qdapDictionaries::deamplification.words,
amplifier.weight = 0.8,
n.before = 4,
n.after = 2,
constrain = TRUE)
t2 <- Sys.time()
t2-t1
beepr::beep(0)
str(sentiments)
stm_data$sentiment <- sentiments$all$polarity
sentiments$group
str(sentiments$all)
sum(is.na(stm_data$sentiment))
stm_data[which(is.na(stm_data$sentiment)),]
summary(stm.data$sentiment)
summary(stm_data$sentiment)
idx <- which(is.na(stm_data$sentiment))
idx
stm_data <- stm_data[-idx,]
pos <- round(sum(stm_data$sentiment > 0, na.rm = TRUE) / length(stm_data$sentiment)*100,2)
pos
neg <- round(sum(stm_data$sentiment < 0, na.rm = TRUE) / length(stm_data$sentiment)*100,2)
neg
neut <- round(sum(stm_data$sentiment == 0, na.rm = TRUE) / length(stm_data$sentiment)*100,2)
neut
hist(stm_data$sentiment)
boxplot(stm_data$sentiment)
boxplot(stm_data$sentiment, range = F)
stop_words <- c(stop_words, "imagejpg", "Subject:", "AM", "PM", month_names, week_days_names)
processed <- textProcessor(stm_data$text,
metadata=stm_data,
stem = FALSE,
striphtml = TRUE,
customstopwords = stop_words)
# Choose frequency threshold
plotRemoved(processed$documents, lower.thresh=seq(from = 1, to = 50, by = 1))
#structure and index for usage in the stm model. Verify no-missingness.
out <- prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 3)
#output will have object meta, documents, and vocab
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ sentiment + to + from + senderId + from_to + released + date + day_month + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
library(WGCNA)
collectGarbage()
getwd()
setwd("/Volumes/uSD128GB/Coding_dojo/dojo_repo/Dojo-repo/Feb-2016-Dojo")
saveRDS(emailsFit, "emailsFit.RDS")
saveRDS(out, "out.RDS")
rm(list = ls())
emailsFit <- readRDS("emailsFit.RDS")
out <- readRDS("our.RDS")
out <- readRDS("out.RDS")
docs <- out$documents
vocab <- out$vocab
meta  <-out$meta
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ sentiment + to + from + from_to + released + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ sentiment + from_to + released + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ sentiment + from_to + released + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
t1 <- Sys.time()
emailsFit <- stm(out$documents,
out$vocab,
K=40,
prevalence = ~ sentiment + from_to + released + day_week + month + year,
max.em.its = 500,
data=out$meta,
seed=5926696,
init.type="Spectral")
t2 <- Sys.time()
t2-t1
beepr::beep(0)
saveRDS(emailsFit, "emailsFit.RDS")
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("sentiment", "from_to", "released", "day_week", "month", "year"),
text = "emails",
id = NULL,
n = 2000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("sentiment", "from_to", "released", "day_week", "month", "year"),
text = "emails",
id = NULL,
n = 7000,
labeltype ="frex") #prob
stmBrowser(mod = emailsFit,
data = out$meta,
covariates = c("sentiment", "from_to", "released", "day_week", "month", "year"),
text = "emails",
id = NULL,
n = 7000,
labeltype ="frex") #prob
install.packages(c("knitr", "servr", "devtools"))     # To process .Rmd files
devtools::install_github("hadley/lubridate")         # brocks reqs dev version
devtools::install_github("brendan-r/brocks")         # My lazy wrapper funs
